{
	"nodes":[
		{"id":"15fb539f63574710","type":"text","text":"### Hadoop: MapReduce\n\n- **Distribution des données**: Les données sont distribuées sur les nœuds du cluster sous forme de blocs, traitées localement pour minimiser le trafic réseau (principe de localisation des données).\n- **Modèle de programmation**: MapReduce simplifie le développement de programmes pour le traitement des données distribuées. Le programme comporte deux fonctions principales: `Map()` et `Reduce()`.\n- **Architecture MR1**: Architecture maître-esclave avec un JobTracker unique qui gère les TaskTrackers.","x":-182,"y":-210,"width":462,"height":250},
		{"id":"ed44522ca6780314","type":"text","text":"### Exemple d'utilisation\n\n- **Objectif**: Compter les occurrences des noms d'animaux dans un fichier texte sur HDFS.\n- **Équivalent SQL**: `SELECT NAME, COUNT(NAME) FROM ANIMALS WHERE NAME IN ('Tiger', 'Lion', ...) GROUP BY NAME;`\n- **Approche MapReduce**:\n    - **Tâche Map**: Filtre et mappe les noms d'animaux en paires clé-valeur `<nom, 1>`.\n    - **Shuffle**: Regroupe les données par nom d'animal.\n    - **Tâche Reduce**: Additionne les valeurs pour compter les occurrences de chaque nom d'animal.","x":-240,"y":140,"width":580,"height":260},
		{"id":"411935f995675aa2","type":"text","text":"### Exécution des Jobs MapReduce\n\n1. **Responsabilités du JobTracker**:\n    \n    - Reçoit et gère les jobs MapReduce.\n    - Communique avec le NameNode pour localiser les données.\n    - Distribue les tâches Map et Reduce aux TaskTrackers.\n    - Surveille les tâches, redémarre celles qui échouent, et informe les clients de l'avancement.\n    - Utilise un algorithme d'ordonnancement FIFO.\n2. **Tâche Map**:\n    \n    - Divise les données en fragments logiques (splits).\n    - Traite chaque split localement, générant des paires clé-valeur.\n    - Transfère les données si nécessaire.\n3. **Shuffle et Sort**:\n    \n    - Regroupe les paires clé-valeur par clé.\n    - Trie et regroupe les données avant la phase Reduce.\n4. **Tâche Reduce**:\n    \n    - Agrège les valeurs pour chaque clé pour produire le résultat final.\n    - Stocke les résultats dans HDFS.","x":380,"y":-292,"width":584,"height":414},
		{"id":"f82d15bff9c50b56","type":"text","text":"### Introduction à Hive\n\n- **Origines**: Développé chez Facebook, maintenant Apache. Surcouche analytique à Hadoop, traite des données structurées.\n- **Utilisation**: Utilisé par des entreprises comme Amazon (AWS). Langage HiveQL (HQL) similaire à SQL pour des requêtes sur Hadoop.\n- **Fonctionnalités**: Supporte les fonctions et procédures utilisateur en Java/Scala.\n\n### Architecture de Hive\n\n- **Clients**: Divers (C++, Java, Python) via JDBC, Thrift, ODBC.\n- **Services**: Interface commandes (CLI), web (Hue), Hive Server.\n- **Driver**: Traite les requêtes, compile, optimise, exécute des jobs MapReduce.\n\n### Stockage et traitement\n\n- **MetaStore**: Base de données relationnelle stockant les métadonnées (schéma, emplacement des fichiers).\n- **Processus**: Requêtes soumises au Driver, compilées, optimisées, exécutées comme jobs MapReduce, résultats dans HDFS.\n\n### Étapes de traitement\n\n1. Soumission de la requête.\n2. Compilation et récupération des métadonnées.\n3. Création du plan d'exécution.\n4. Exécution sur le cluster Hadoop.\n5. Stockage des résultats dans HDFS.\n\n### Configurations et commandes\n\n- **Configuration**: `hive-site.xml`.\n- **Commandes**: `hive` (connexion directe), `beeline` (connexions JDBC).\n\n### Gestion des bases de données et des tables\n\n- **Création de BD**: `CREATE DATABASE`.\n- **Tables internes/externes**: Internes (données et métadonnées supprimées ensemble), externes (seules métadonnées supprimées).\n- **Création de table**: `CREATE [EXTERNAL] TABLE`.\n- **Chargement de données**: `LOAD DATA [LOCAL] INPATH`.\n\n### Formats de fichiers\n\n- **Supportés**: Texte, CSV, JSON, SequenceFile, Avro, RCFile, ORC, Parquet.\n- **Colonnes**: RC, ORC, Parquet.\n- **Compression**: Options pour les fichiers SequenceFile.","x":-353,"y":520,"width":805,"height":990},
		{"id":"1fe7752b42410a1c","type":"text","text":"### Phases de MapReduce\n\n- **Phase Map**: Exécute la fonction Map sur chaque split, produisant des paires clé-valeur intermédiaires.\n- **Phase Shuffle**: Transfère et trie les données intermédiaires, regroupant toutes les valeurs pour une même clé.\n- **Phase Reduce**: Applique la fonction Reduce aux paires clé-valeur agrégées et stocke les résultats dans HDFS.","x":1060,"y":-193,"width":493,"height":216},
		{"id":"b66eb2652d58df8a","type":"text","text":"### Réponses simplifiées aux questions sur MapReduce\n\n1. **C'est quoi le principe de MapReduce ?**\n    \n    - Diviser les données en blocs, traiter chaque bloc localement pour minimiser les échanges réseaux​​.\n2. **C'est quoi l'intérêt de MapReduce ?**\n    \n    - Simplifie le traitement de grandes quantités de données en se concentrant sur l'algorithme, pas sur la gestion de la distribution et de la parallélisation​​.\n3. **Définir l'architecture MapReduce**\n    \n    - Modèle maître/esclave : un JobTracker contrôle les TaskTrackers qui exécutent les tâches​​.\n4. **Définir JobTracker**\n    \n    - Gère les jobs MapReduce, assigne les tâches aux TaskTrackers et surveille leur exécution​​.\n5. **Définir TaskTracker**\n    \n    - Exécute les tâches Map et Reduce, rapporte son statut au JobTracker​​.\n6. **Définir le modèle de programmation Map**\n    \n    - Traite des blocs de données, produit des paires clé-valeur pour chaque entrée​​.\n7. **Définir le modèle de programmation Reduce**\n    \n    - Agrège les paires clé-valeur produites par les tâches Map et génère le résultat final​​.\n8. **Expliquer la phase Map**\n    \n    - Analyse et transforme les données d'entrée en paires clé-valeur​​.\n9. **Expliquer la phase Reduce**\n    \n    - Agrège et traite les paires clé-valeur par clé, écrit les résultats​​.\n10. **Expliquer la phase de shuffle**\n    \n    - Regroupe et trie les paires clé-valeur de la phase Map avant la phase Reduce​​.\n11. **Expliquer la phase reducer**\n    \n    - Traite les valeurs associées à chaque clé, génère et écrit les résultats​​.\n12. **Expliquer la phase Combine**\n    \n    - Optionnelle, réduit la quantité de données transférées en agrégeant localement les résultats de la phase Map​​.\n13. **C'est quoi SPLITS ?**\n    \n    - Divisions des données d'entrée pour être traitées individuellement par les tâches Map​​.\n14. **Donner trois classes principales lisent des données dans MapReduce**\n    \n    - `FileInputFormat`, `TextInputFormat`, `SequenceFileInputFormat`​​.\n15. **C'est quoi RecordReader ?**\n    \n    - Convertit les données d'entrée en paires clé-valeur pour les tâches Map​​.\n16. **Donner les étapes de l'exécution d'un job**\n    \n    1. Création du programme.\n    2. Envoi de la demande au JobTracker.\n    3. Calcul des splits.\n    4. Copie des ressources dans HDFS.\n    5. Assignation des tâches aux TaskTrackers.\n    6. Exécution des tâches Map.\n    7. Phase de shuffle.\n    8. Exécution des tâches Reduce.\n    9. Écriture des résultats dans HDFS​​.","x":-1180,"y":-402,"width":660,"height":1002}
	],
	"edges":[
		{"id":"82efd4dcf05efb7d","fromNode":"15fb539f63574710","fromSide":"right","toNode":"411935f995675aa2","toSide":"left"},
		{"id":"c9979bd7798cf232","fromNode":"15fb539f63574710","fromSide":"bottom","toNode":"ed44522ca6780314","toSide":"top"},
		{"id":"f546c2576cd4e75a","fromNode":"411935f995675aa2","fromSide":"right","toNode":"1fe7752b42410a1c","toSide":"left"}
	]
}